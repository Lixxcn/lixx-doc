

第一章 什么是大语言模型

马少平 清华大学 计算机系

面向人工智能初学者的通俗讲座

《计算机是如何实现智能的》之

B站 获取PPT 跟我学AI公众号

大语言模型

ChatGPT

q 人工智能迈上新台阶

DeepSeek

q 高性能

q 低成本

q 国产化

q 开源化

大语言模型

语言理解能力

语言生成能力

多轮对话管理能力

一定的逻辑推理能力

数据+知识

q 数据与知识的统一化处理

幻觉问题

什么是大语言模型

语言模型

“天气预报大风降温，我明天要多___”

?(??|?1, ?2, …, ??−1)

大语言模型

q n：多达百万

q 参数：

ChatGPT：175B=1750亿

DeepSeek：671B=6710亿

穿衣服

喝热水

开暖气

唱歌

跑步

大语言模型的基本功能

下一个单词预测

q token

q 文字接龙

黄 白日依山尽的下一句是

白日依山尽的下一句是 黄 河

白日依山尽的下一句是 黄河 入

白日依山尽的下一句是 黄河入 海

白日依山尽的下一句是 黄河入海 流

白日依山尽的下一句是 黄河入海流 <结束符>

预训练模型

鹦鹉学舌

见多识广

熟读唐诗三百首，不会做诗也会吟

关键技术

基于注意力机制的词向量动态表示

词的语义由其所在的上下文决定

“我吃了一个非常美味的苹果”

“我用苹果跟朋友联系”

注意力机制

认知心理学

q 选择性注意现象

注意力机制

词的语义由其所在上下文中与其相关的词决定

实现词向量的动态表示

解决长距离依赖问题

“一回到家我就吃了一个非常美味的苹果”

“一回到家我就用苹果跟朋友联系”

水果

手机

预训练模型

鹦鹉可以学舌

麻雀会学舌吗？

Transformer模型

编码层

……

编码层

输入层

输入序列

解码层

……

解码层

输入层

输出层

已生成输出序列

下一个单词概率

中间表示序列

语法信息

语义信息

语义信息

语法信息

编

码

器

解

码

器

基于人类反馈的强化学习

幻觉问题

幻觉问题

两个例子

3.9和3.11哪个大？

草莓的英文中有几个r？

q Strawberry

幻觉

q 概率约束下的随机选择

q 本质是猜测

幻觉问题举例

请写一个清华大学计算机系马少平的简历。

马少平，男，汉族，1964年出生，中共党员，博士研究生学历，教授，博士生导师。现任清华大

学计算机系副主任，人工智能实验室主任。

教育背景：

1981年-1985年，清华大学计算机科学与技术专业，学士学位；

1985年-1988年，清华大学计算机科学与技术专业，硕士学位；

1990年-1994年，清华大学计算机科学与技术专业，博士学位。

工作经历：

1988年-1990年，清华大学计算机系，助教；

1994年-1996年，清华大学计算机系，讲师；

1996年-2000年，清华大学计算机系，副教授；

2000年至今，清华大学计算机系，教授；

2003年至今，清华大学计算机系，博士生导师；

2008年至今，清华大学计算机系，副主任；

2010年至今，清华大学人工智能实验室，主任。

为什么会出现幻觉？

幻觉

q 概率约束下的随机选择

q 本质是猜测

幻觉：一把双刃剑

DeepSeek的特点

混合专家模型

DeepSeek v3中每次仅激活6710亿个参数中的370亿个

DeepSeek的特点

GRPO算法

传统方法

q 基于演员-评论家模型

q PPO算法

DeepSeek的特点

GRPO算法

q 代替PPO算法

q 通过组内奖励特性替代PPO中的价值网络（Critic）

q 只需训练一个主模型

q 有效降低了显存资源消耗

q 有效提高了训练效率

DeepSeek的特点

多词元（token）预测MTP

传统方法

q 一次预测一个词元

MTP的优势

q 并行多词元预测

q 提高训练效率

q 提高文本生成质量

解码层

……

解码层

输入层

输出层

输入+已生成输出序列

下一个词元概率

??

0

??

1

??

?

??

?−1

位置序列??

多个词元概率