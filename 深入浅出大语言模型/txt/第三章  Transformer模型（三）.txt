第三章 Transformer模型（三）


3.4 多头注意力机制

多视角学习

q 一句话可能表达多个语义

q 单一注意力机制

只关注单一注意力模式

可能被少数强相关词主导

q 多头注意力机制

多个注意力机制联合作用

从不同的视角关注多样化的注意力模式

类比卷积神经网络中的多卷积核

3.4 多头注意力机制

基本思想

q 将Q、K、V分别变换到h个子空间

其中??、 ??、 ??均为d行?ℎ列矩阵

q 在子空间计算注意力机制

q 由注意力机制：

q 有：

?′

= ??? ?′

= ??? ?′

= ???

𝑎? ?′

,?′

, ?′ = 𝑎? ???,???, ??? 

= 𝑠𝑎??? ???

 ???

 ?

?

 ∙ ???

𝑎? ?,?, ? = 𝑠𝑎??? ??

?

?

 ∙ ?

3.4 多头注意力机制

为方便起见子空间的注意力机制还是用𝑎? ?,?, ? 表示：

一组变换对应一个注意力机制

h组变换对应h个注意力机制

称作多头注意力机制

𝑎? ?,?, ? = 𝑎? ???,???, ??? 

= 𝑠𝑎??? ???

 ???

 ?

?

 ∙ ???

3.4 多头注意力机制

设第i个头的三个变换矩阵分别为??

 ? 

、??

 ? 

、??

 ? 

，均为d行?ℎ列

第i个头的自注意力矩阵??（ n行?ℎ列）为：

将h个??拼接在一起组成矩阵U（ n行ℎ ∙ ?ℎ列）：

q 其中“

；

”表示拼接

?? = 𝑎? ???

 ? 

,???

 ? 

, ???

 ? , ? = 1,2, …, ℎ

? = ?1;?2; …;?ℎ

 

3.4 多头注意力机制

例：设词向量的维度是4、输入序列长度为5、具有3个头的自注意力

机制，每个头的输出维度为2，则??是一个5行4列的矩阵，其中

i=1,2,3

?1 =

 

 

 

 

 

1

1

1

2

1

1

,

, 1

1

1

2

2

2

,

, 1

1

1

2

3

3

,

,1

1

2

1

4

4

131, 132, 133,134

141, 142, 143,144

151, 152, 153,154

 

 

 

 

 

?2 =

 

 

 

 

 

2

2

1

2

1

1

,

, 2

2

1

2

2

2

,

, 2

2

1

2

3

3

,

,2

2

1

2

4

4

231, 232, 233,234

241, 242, 243,244

251, 252, 253,254

 

 

 

 

 

?3 =

 

 

 

 

 

311, 312, 313,314

321, 322, 323,324

331, 332, 333,334

341, 342, 343,344

351, 352, 353,354

 

 

 

 

 

?

=

 

 

 

 

 

1

1

1

2

1

1

,

,1

1

1

2

2

2

,

,1

1

1

2

3

3

,

,1

1

1

2

4

4

, 131, 132, 133,134

141, 142, 143,144

151, 152, 153,154

, 2

2

2

1

1

1

,

, 2

2

2

1

2

2

,

, 2

2

2

1

3

3

,

,2

2

2

1

4

4

, 231, 232, 233,234

, 241, 242, 243,244

, 251, 252, 253,254

,

, 3

3

1

2

1

1

,

, 3

3

1

2

2

2

,

, 3

3

1

2

3

3

,

,3

3

1

2

4

4

, 331, 332, 333,334

, 341, 342, 343,344

, 351, 352, 353,354

 

 

 

 

 

3.4 多头注意力机制

对U右乘ℎ ∙ ?ℎ行d列矩阵??，将在多个子空间得到的注意力结果整合

在一起，就得到了多头注意力矩阵（n行d列）：

如果?ℎ =

?

ℎ

，则无需右乘??

多头自注意力机制：

??

 ? 

、??

 ? 

、??

 ? 

、 ??均通过训练得到

𝑚𝑎?_𝑎? ?,?, ? = ? ∙ ??

𝑚𝑎?_𝑎? ?, ?, ? 
